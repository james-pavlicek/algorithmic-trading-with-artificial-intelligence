{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the 3rd part of Utilizing Artificial Intelligence for Algorithmic Trading.\n",
    "For this part we will be testing the models built in step 2. This step will also introduce the sentiment models that do not require testing.\n",
    "The result of this script will be a .csv that will be used in step 4 where we build the meta models.\n",
    "\n",
    "This code has been built for a large scale research project for Texas State University.\n",
    "The research for the project has been conducted by James Pavlicek, Jack Burt, and Andrew Hocher.\n",
    "If you have any questions or inquiries feel free to reach out to me at https://www.jamespavlicek.com/ \n",
    "This code is free use and anyone can use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import re, string, unicodedata \n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from joblib import dump\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the dataset from the train/test split in step 2. Remember to set your own path.\n",
    "data = pd.read_csv(\"/Users/jamespavlicek/Desktop/QMST/4320/Project Final/test_data.csv\")\n",
    "\n",
    "df = data.copy()\n",
    "df_2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6082, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6082 rows and 9 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>item 7. management's discussion and analysis o...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>item 7. management's discussion and analysis o...</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification  \\\n",
       "0  services-computer integrated systems design [7...   \n",
       "1  savings institutions, not federally chartered ...   \n",
       "2                          operative builders [1531]   \n",
       "3                              life insurance [6311]   \n",
       "4          electric & other services combined [4931]   \n",
       "\n",
       "                                        Largest Text Ticker  \\\n",
       "0  item 7. management s discussion and analysis o...   CLSK   \n",
       "1  item 7. management's discussion and analysis o...   HFWA   \n",
       "2  item 7. management s discussion and analysis o...    PHM   \n",
       "3  item 7. management s discussion and analysis o...    MET   \n",
       "4  item 7. management's discussion and analysis o...    EXC   \n",
       "\n",
       "   Percent Change (1 Week) Return Type  \n",
       "0                -0.106524    Negative  \n",
       "1                 0.008755    Positive  \n",
       "2                 0.071569    Positive  \n",
       "3                 0.010058    Positive  \n",
       "4                 0.024268    Positive  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>20200218_10-K_edgar_data_1360604_0001360604-20...</td>\n",
       "      <td>healthcare trust of america, inc.</td>\n",
       "      <td>20200218</td>\n",
       "      <td>1360604</td>\n",
       "      <td>real estate investment trusts [6798]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>HR</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>20230228_10-K_edgar_data_1411579_0001411579-23...</td>\n",
       "      <td>amc entertainment holdings, inc.</td>\n",
       "      <td>20230228</td>\n",
       "      <td>1411579</td>\n",
       "      <td>services-motion picture theaters [7830]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>AMC</td>\n",
       "      <td>-0.124650</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>20170228_10-K_edgar_data_1163302_0001163302-17...</td>\n",
       "      <td>united states steel corp</td>\n",
       "      <td>20170228</td>\n",
       "      <td>1163302</td>\n",
       "      <td>steel works, blast furnaces  rolling mills (co...</td>\n",
       "      <td>item 7. management's discussion and analysis o...</td>\n",
       "      <td>X</td>\n",
       "      <td>-0.032025</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>20090331_10-K_edgar_data_43196_0000950144-09-0...</td>\n",
       "      <td>gray television inc</td>\n",
       "      <td>20090331</td>\n",
       "      <td>43196</td>\n",
       "      <td>television broadcasting stations [4833]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>GTN</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>20200316_10-K_edgar_data_1468748_0001564590-20...</td>\n",
       "      <td>kodiak sciences inc.</td>\n",
       "      <td>20200316</td>\n",
       "      <td>1468748</td>\n",
       "      <td>biological products (no diagnostic substances)...</td>\n",
       "      <td>item 7. management s discussion and analys is ...</td>\n",
       "      <td>KOD</td>\n",
       "      <td>0.116291</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filename  \\\n",
       "6077  20200218_10-K_edgar_data_1360604_0001360604-20...   \n",
       "6078  20230228_10-K_edgar_data_1411579_0001411579-23...   \n",
       "6079  20170228_10-K_edgar_data_1163302_0001163302-17...   \n",
       "6080  20090331_10-K_edgar_data_43196_0000950144-09-0...   \n",
       "6081  20200316_10-K_edgar_data_1468748_0001564590-20...   \n",
       "\n",
       "                           Company Name  Filed As Of Date  Central Index Key  \\\n",
       "6077  healthcare trust of america, inc.          20200218            1360604   \n",
       "6078   amc entertainment holdings, inc.          20230228            1411579   \n",
       "6079           united states steel corp          20170228            1163302   \n",
       "6080                gray television inc          20090331              43196   \n",
       "6081               kodiak sciences inc.          20200316            1468748   \n",
       "\n",
       "                     Standard Industrial Classification  \\\n",
       "6077               real estate investment trusts [6798]   \n",
       "6078            services-motion picture theaters [7830]   \n",
       "6079  steel works, blast furnaces  rolling mills (co...   \n",
       "6080            television broadcasting stations [4833]   \n",
       "6081  biological products (no diagnostic substances)...   \n",
       "\n",
       "                                           Largest Text Ticker  \\\n",
       "6077  item 7. management s discussion and analysis o...     HR   \n",
       "6078  item 7. management s discussion and analysis o...    AMC   \n",
       "6079  item 7. management's discussion and analysis o...      X   \n",
       "6080  item 7. management s discussion and analysis o...    GTN   \n",
       "6081  item 7. management s discussion and analys is ...    KOD   \n",
       "\n",
       "      Percent Change (1 Week) Return Type  \n",
       "6077                 0.013804    Positive  \n",
       "6078                -0.124650    Negative  \n",
       "6079                -0.032025    Negative  \n",
       "6080                 0.406250    Positive  \n",
       "6081                 0.116291    Positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>20210310_10-K_edgar_data_1747079_0001747079-21...</td>\n",
       "      <td>bally's corp</td>\n",
       "      <td>20210310</td>\n",
       "      <td>1747079</td>\n",
       "      <td>hotels &amp; motels [7011]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>BALY</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>20140415_10-K_edgar_data_1108046_0001477932-14...</td>\n",
       "      <td>alumifuel power corp</td>\n",
       "      <td>20140415</td>\n",
       "      <td>1108046</td>\n",
       "      <td>industrial organic chemicals [2860]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>AFPW</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>20170331_10-K_edgar_data_829325_0001262463-17-...</td>\n",
       "      <td>spyr, inc.</td>\n",
       "      <td>20170331</td>\n",
       "      <td>829325</td>\n",
       "      <td>retail-eating &amp; drinking places [5810]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>SPYR</td>\n",
       "      <td>-0.001857</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>20140319_10-K_edgar_data_1364479_0001364479-14...</td>\n",
       "      <td>hertz global holdings inc</td>\n",
       "      <td>20140319</td>\n",
       "      <td>1364479</td>\n",
       "      <td>services-auto rental &amp; leasing (no drivers) [7...</td>\n",
       "      <td>item 7. management's discussion and analysis o...</td>\n",
       "      <td>HRI</td>\n",
       "      <td>-0.032139</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>20170228_10-K_edgar_data_1093557_0001093557-17...</td>\n",
       "      <td>dexcom inc</td>\n",
       "      <td>20170228</td>\n",
       "      <td>1093557</td>\n",
       "      <td>surgical &amp; medical instruments &amp; apparatus [3841]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>DXCM</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>20140227_10-K_edgar_data_60519_0001504337-14-0...</td>\n",
       "      <td>louisiana-pacific corp</td>\n",
       "      <td>20140227</td>\n",
       "      <td>60519</td>\n",
       "      <td>lumber &amp; wood products (no furniture) [2400]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>LPX</td>\n",
       "      <td>-0.019282</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>20230314_10-K_edgar_data_771266_0001493152-23-...</td>\n",
       "      <td>kopin corp</td>\n",
       "      <td>20230314</td>\n",
       "      <td>771266</td>\n",
       "      <td>semiconductors &amp; related devices [3674]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>KOPN</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>20211215_10-K_edgar_data_1410738_0001493152-21...</td>\n",
       "      <td>voip-pal.com inc</td>\n",
       "      <td>20211215</td>\n",
       "      <td>1410738</td>\n",
       "      <td>telephone &amp; telegraph apparatus [3661]</td>\n",
       "      <td>item 7. management s discussion and analysis o...</td>\n",
       "      <td>VPLM</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>20220517_10-K_edgar_data_946581_0001628280-22-...</td>\n",
       "      <td>take two interactive software inc</td>\n",
       "      <td>20220517</td>\n",
       "      <td>946581</td>\n",
       "      <td>services-prepackaged software [7372]</td>\n",
       "      <td>item 7. management's discussion and analysis o...</td>\n",
       "      <td>TTWO</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>20020322_10-K_edgar_data_833640_0001012870-02-...</td>\n",
       "      <td>power integrations inc</td>\n",
       "      <td>20020322</td>\n",
       "      <td>833640</td>\n",
       "      <td>semiconductors &amp; related devices [3674]</td>\n",
       "      <td>item 7. management's discussion and analysis o...</td>\n",
       "      <td>POWI</td>\n",
       "      <td>0.014917</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filename  \\\n",
       "2482  20210310_10-K_edgar_data_1747079_0001747079-21...   \n",
       "4189  20140415_10-K_edgar_data_1108046_0001477932-14...   \n",
       "2806  20170331_10-K_edgar_data_829325_0001262463-17-...   \n",
       "625   20140319_10-K_edgar_data_1364479_0001364479-14...   \n",
       "5261  20170228_10-K_edgar_data_1093557_0001093557-17...   \n",
       "2187  20140227_10-K_edgar_data_60519_0001504337-14-0...   \n",
       "1558  20230314_10-K_edgar_data_771266_0001493152-23-...   \n",
       "889   20211215_10-K_edgar_data_1410738_0001493152-21...   \n",
       "463   20220517_10-K_edgar_data_946581_0001628280-22-...   \n",
       "5970  20020322_10-K_edgar_data_833640_0001012870-02-...   \n",
       "\n",
       "                           Company Name  Filed As Of Date  Central Index Key  \\\n",
       "2482                       bally's corp          20210310            1747079   \n",
       "4189               alumifuel power corp          20140415            1108046   \n",
       "2806                         spyr, inc.          20170331             829325   \n",
       "625           hertz global holdings inc          20140319            1364479   \n",
       "5261                         dexcom inc          20170228            1093557   \n",
       "2187             louisiana-pacific corp          20140227              60519   \n",
       "1558                         kopin corp          20230314             771266   \n",
       "889                    voip-pal.com inc          20211215            1410738   \n",
       "463   take two interactive software inc          20220517             946581   \n",
       "5970             power integrations inc          20020322             833640   \n",
       "\n",
       "                     Standard Industrial Classification  \\\n",
       "2482                             hotels & motels [7011]   \n",
       "4189                industrial organic chemicals [2860]   \n",
       "2806             retail-eating & drinking places [5810]   \n",
       "625   services-auto rental & leasing (no drivers) [7...   \n",
       "5261  surgical & medical instruments & apparatus [3841]   \n",
       "2187       lumber & wood products (no furniture) [2400]   \n",
       "1558            semiconductors & related devices [3674]   \n",
       "889              telephone & telegraph apparatus [3661]   \n",
       "463                services-prepackaged software [7372]   \n",
       "5970            semiconductors & related devices [3674]   \n",
       "\n",
       "                                           Largest Text Ticker  \\\n",
       "2482  item 7. management s discussion and analysis o...   BALY   \n",
       "4189  item 7. management s discussion and analysis o...   AFPW   \n",
       "2806  item 7. management s discussion and analysis o...   SPYR   \n",
       "625   item 7. management's discussion and analysis o...    HRI   \n",
       "5261  item 7. management s discussion and analysis o...   DXCM   \n",
       "2187  item 7. management s discussion and analysis o...    LPX   \n",
       "1558  item 7. management s discussion and analysis o...   KOPN   \n",
       "889   item 7. management s discussion and analysis o...   VPLM   \n",
       "463   item 7. management's discussion and analysis o...   TTWO   \n",
       "5970  item 7. management's discussion and analysis o...   POWI   \n",
       "\n",
       "      Percent Change (1 Week) Return Type  \n",
       "2482                 0.003616    Positive  \n",
       "4189                -0.125000    Negative  \n",
       "2806                -0.001857    Negative  \n",
       "625                 -0.032139    Negative  \n",
       "5261                 0.002559    Positive  \n",
       "2187                -0.019282    Negative  \n",
       "1558                -0.049505    Negative  \n",
       "889                 -0.076923    Negative  \n",
       "463                  0.004387    Positive  \n",
       "5970                 0.014917    Positive  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filename                              0\n",
       "Company Name                          0\n",
       "Filed As Of Date                      0\n",
       "Central Index Key                     0\n",
       "Standard Industrial Classification    0\n",
       "Largest Text                          0\n",
       "Ticker                                0\n",
       "Percent Change (1 Week)               0\n",
       "Return Type                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[data.duplicated()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6082 entries, 0 to 6081\n",
      "Data columns (total 9 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Filename                            6082 non-null   object \n",
      " 1   Company Name                        6082 non-null   object \n",
      " 2   Filed As Of Date                    6082 non-null   int64  \n",
      " 3   Central Index Key                   6082 non-null   int64  \n",
      " 4   Standard Industrial Classification  6082 non-null   object \n",
      " 5   Largest Text                        6082 non-null   object \n",
      " 6   Ticker                              6082 non-null   object \n",
      " 7   Percent Change (1 Week)             6082 non-null   float64\n",
      " 8   Return Type                         6082 non-null   object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 427.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filename                              0\n",
       "Company Name                          0\n",
       "Filed As Of Date                      0\n",
       "Central Index Key                     0\n",
       "Standard Industrial Classification    0\n",
       "Largest Text                          0\n",
       "Ticker                                0\n",
       "Percent Change (1 Week)               0\n",
       "Return Type                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <td>6082.0</td>\n",
       "      <td>2.016275e+07</td>\n",
       "      <td>60619.844668</td>\n",
       "      <td>2.000022e+07</td>\n",
       "      <td>2.013021e+07</td>\n",
       "      <td>2.018030e+07</td>\n",
       "      <td>2.021032e+07</td>\n",
       "      <td>2.023123e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central Index Key</th>\n",
       "      <td>6082.0</td>\n",
       "      <td>1.002136e+06</td>\n",
       "      <td>522685.163134</td>\n",
       "      <td>1.750000e+03</td>\n",
       "      <td>7.977210e+05</td>\n",
       "      <td>1.046568e+06</td>\n",
       "      <td>1.409056e+06</td>\n",
       "      <td>1.907982e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <td>6082.0</td>\n",
       "      <td>8.449757e-05</td>\n",
       "      <td>0.122309</td>\n",
       "      <td>-6.949153e-01</td>\n",
       "      <td>-3.241883e-02</td>\n",
       "      <td>-5.594605e-04</td>\n",
       "      <td>2.729096e-02</td>\n",
       "      <td>4.869565e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count          mean            std           min  \\\n",
       "Filed As Of Date         6082.0  2.016275e+07   60619.844668  2.000022e+07   \n",
       "Central Index Key        6082.0  1.002136e+06  522685.163134  1.750000e+03   \n",
       "Percent Change (1 Week)  6082.0  8.449757e-05       0.122309 -6.949153e-01   \n",
       "\n",
       "                                  25%           50%           75%  \\\n",
       "Filed As Of Date         2.013021e+07  2.018030e+07  2.021032e+07   \n",
       "Central Index Key        7.977210e+05  1.046568e+06  1.409056e+06   \n",
       "Percent Change (1 Week) -3.241883e-02 -5.594605e-04  2.729096e-02   \n",
       "\n",
       "                                  max  \n",
       "Filed As Of Date         2.023123e+07  \n",
       "Central Index Key        1.907982e+06  \n",
       "Percent Change (1 Week)  4.869565e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean length of the 'Largest Text' entries is: 105697.17264057876\n"
     ]
    }
   ],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "df[\"Largest Text\"] = df[\"Largest Text\"].apply(lambda x: strip_html(x))\n",
    "\n",
    "df.head()\n",
    "\n",
    "mean_length = df['Largest Text'].apply(len).mean()\n",
    "print(f\"The mean length of the 'Largest Text' entries is: {mean_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Contractions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "df[\"Largest Text\"] = df[\"Largest Text\"].apply(lambda x: replace_contractions(x))\n",
    "\n",
    "df.head()\n",
    "\n",
    "df_3 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Numbers/Special Characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean length of the 'Largest Text' entries is: 99054.97435054259\n"
     ]
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits=True):\n",
    "    special = r\"[^a-zA-Z0-9\\s]\" if not remove_digits else r\"[^a-zA-z\\s]\"\n",
    "    text = re.sub(special, \"\", text)\n",
    "    return text\n",
    "\n",
    "df[\"Largest Text\"] = df[\"Largest Text\"].apply(lambda x: remove_special_characters(x))\n",
    "\n",
    "df.head()\n",
    "\n",
    "mean_length = df['Largest Text'].apply(len).mean()\n",
    "print(f\"The mean length of the 'Largest Text' entries is: {mean_length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to Lowercase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>item  management s discussion and analysis of ...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>item  managements discussion and analysis of f...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>item  management s discussion and analysis of ...</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>item  management s discussion and analysis of ...</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>item  managements discussion and analysis of f...</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification  \\\n",
       "0  services-computer integrated systems design [7...   \n",
       "1  savings institutions, not federally chartered ...   \n",
       "2                          operative builders [1531]   \n",
       "3                              life insurance [6311]   \n",
       "4          electric & other services combined [4931]   \n",
       "\n",
       "                                        Largest Text Ticker  \\\n",
       "0  item  management s discussion and analysis of ...   CLSK   \n",
       "1  item  managements discussion and analysis of f...   HFWA   \n",
       "2  item  management s discussion and analysis of ...    PHM   \n",
       "3  item  management s discussion and analysis of ...    MET   \n",
       "4  item  managements discussion and analysis of f...    EXC   \n",
       "\n",
       "   Percent Change (1 Week) Return Type  \n",
       "0                -0.106524    Negative  \n",
       "1                 0.008755    Positive  \n",
       "2                 0.071569    Positive  \n",
       "3                 0.010058    Positive  \n",
       "4                 0.024268    Positive  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_lowercase(text):\n",
    "    lower = text.lower()\n",
    "    return lower\n",
    "\n",
    "df[\"Largest Text\"] = df[\"Largest Text\"].apply(lambda x: to_lowercase(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>[item, management, s, discussion, and, analysi...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>[item, managements, discussion, and, analysis,...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>[item, management, s, discussion, and, analysi...</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>[item, management, s, discussion, and, analysi...</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>[item, managements, discussion, and, analysis,...</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification  \\\n",
       "0  services-computer integrated systems design [7...   \n",
       "1  savings institutions, not federally chartered ...   \n",
       "2                          operative builders [1531]   \n",
       "3                              life insurance [6311]   \n",
       "4          electric & other services combined [4931]   \n",
       "\n",
       "                                        Largest Text Ticker  \\\n",
       "0  [item, management, s, discussion, and, analysi...   CLSK   \n",
       "1  [item, managements, discussion, and, analysis,...   HFWA   \n",
       "2  [item, management, s, discussion, and, analysi...    PHM   \n",
       "3  [item, management, s, discussion, and, analysi...    MET   \n",
       "4  [item, managements, discussion, and, analysis,...    EXC   \n",
       "\n",
       "   Percent Change (1 Week) Return Type  \n",
       "0                -0.106524    Negative  \n",
       "1                 0.008755    Positive  \n",
       "2                 0.071569    Positive  \n",
       "3                 0.010058    Positive  \n",
       "4                 0.024268    Positive  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Largest Text'] = df['Largest Text'].astype(str)\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, \"Largest Text\"] = nltk.word_tokenize(row[\"Largest Text\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean length of the 'Largest Text' entries is: 14714.792009207498\n"
     ]
    }
   ],
   "source": [
    "mean_length = df['Largest Text'].apply(len).mean()\n",
    "print(f\"The mean length of the 'Largest Text' entries is: {mean_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words(\"english\")\n",
    "\n",
    "customlist = [\n",
    "    \"not\",\n",
    "    \"could\",\n",
    "    \"did\",\n",
    "    \"does\",\n",
    "    \"had\",\n",
    "    \"has\",\n",
    "    \"have\",\n",
    "    \"is\",\n",
    "    \"ma\",\n",
    "    \"might\",\n",
    "    \"must\",\n",
    "    \"need\",\n",
    "    \"shall\",\n",
    "    \"should\",\n",
    "    \"was\",\n",
    "    \"were\",\n",
    "    \"will\",\n",
    "    \"would\",\n",
    "]\n",
    "\n",
    "stopwords = list(set(stopwords) - set(customlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>[item, management, discussion, analysis, finan...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>[item, managements, discussion, analysis, fina...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>[item, management, discussion, analysis, finan...</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>[item, management, discussion, analysis, finan...</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>[item, managements, discussion, analysis, fina...</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification  \\\n",
       "0  services-computer integrated systems design [7...   \n",
       "1  savings institutions, not federally chartered ...   \n",
       "2                          operative builders [1531]   \n",
       "3                              life insurance [6311]   \n",
       "4          electric & other services combined [4931]   \n",
       "\n",
       "                                        Largest Text Ticker  \\\n",
       "0  [item, management, discussion, analysis, finan...   CLSK   \n",
       "1  [item, managements, discussion, analysis, fina...   HFWA   \n",
       "2  [item, management, discussion, analysis, finan...    PHM   \n",
       "3  [item, management, discussion, analysis, finan...    MET   \n",
       "4  [item, managements, discussion, analysis, fina...    EXC   \n",
       "\n",
       "   Percent Change (1 Week) Return Type  \n",
       "0                -0.106524    Negative  \n",
       "1                 0.008755    Positive  \n",
       "2                 0.071569    Positive  \n",
       "3                 0.010058    Positive  \n",
       "4                 0.024268    Positive  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "df[\"Largest Text\"] = df[\"Largest Text\"].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>[item, management, discussion, analysis, finan...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>[item, managements, discussion, analysis, fina...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>[item, management, discussion, analysis, finan...</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>[item, management, discussion, analysis, finan...</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>[item, managements, discussion, analysis, fina...</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification  \\\n",
       "0  services-computer integrated systems design [7...   \n",
       "1  savings institutions, not federally chartered ...   \n",
       "2                          operative builders [1531]   \n",
       "3                              life insurance [6311]   \n",
       "4          electric & other services combined [4931]   \n",
       "\n",
       "                                        Largest Text Ticker  \\\n",
       "0  [item, management, discussion, analysis, finan...   CLSK   \n",
       "1  [item, managements, discussion, analysis, fina...   HFWA   \n",
       "2  [item, management, discussion, analysis, finan...    PHM   \n",
       "3  [item, management, discussion, analysis, finan...    MET   \n",
       "4  [item, managements, discussion, analysis, fina...    EXC   \n",
       "\n",
       "   Percent Change (1 Week) Return Type  \n",
       "0                -0.106524    Negative  \n",
       "1                 0.008755    Positive  \n",
       "2                 0.071569    Positive  \n",
       "3                 0.010058    Positive  \n",
       "4                 0.024268    Positive  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_list(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "    return new_words\n",
    "\n",
    "df[\"Largest Text\"] = df[\"Largest Text\"].apply(lambda x: lemmatize_list(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word List to Text String "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification  \\\n",
       "0  services-computer integrated systems design [7...   \n",
       "1  savings institutions, not federally chartered ...   \n",
       "2                          operative builders [1531]   \n",
       "3                              life insurance [6311]   \n",
       "4          electric & other services combined [4931]   \n",
       "\n",
       "                                        Largest Text Ticker  \\\n",
       "0  item management discussion analysis financial ...   CLSK   \n",
       "1  item managements discussion analysis financial...   HFWA   \n",
       "2  item management discussion analysis financial ...    PHM   \n",
       "3  item management discussion analysis financial ...    MET   \n",
       "4  item managements discussion analysis financial...    EXC   \n",
       "\n",
       "   Percent Change (1 Week) Return Type  \n",
       "0                -0.106524    Negative  \n",
       "1                 0.008755    Positive  \n",
       "2                 0.071569    Positive  \n",
       "3                 0.010058    Positive  \n",
       "4                 0.024268    Positive  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_words(words):\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"Largest Text\"] = df[\"Largest Text\"].apply(lambda x: join_words(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>20200218_10-K_edgar_data_1360604_0001360604-20...</td>\n",
       "      <td>healthcare trust of america, inc.</td>\n",
       "      <td>20200218</td>\n",
       "      <td>1360604</td>\n",
       "      <td>real estate investment trusts [6798]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>HR</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>20230228_10-K_edgar_data_1411579_0001411579-23...</td>\n",
       "      <td>amc entertainment holdings, inc.</td>\n",
       "      <td>20230228</td>\n",
       "      <td>1411579</td>\n",
       "      <td>services-motion picture theaters [7830]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>AMC</td>\n",
       "      <td>-0.124650</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>20170228_10-K_edgar_data_1163302_0001163302-17...</td>\n",
       "      <td>united states steel corp</td>\n",
       "      <td>20170228</td>\n",
       "      <td>1163302</td>\n",
       "      <td>steel works, blast furnaces  rolling mills (co...</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>X</td>\n",
       "      <td>-0.032025</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>20090331_10-K_edgar_data_43196_0000950144-09-0...</td>\n",
       "      <td>gray television inc</td>\n",
       "      <td>20090331</td>\n",
       "      <td>43196</td>\n",
       "      <td>television broadcasting stations [4833]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>GTN</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>20200316_10-K_edgar_data_1468748_0001564590-20...</td>\n",
       "      <td>kodiak sciences inc.</td>\n",
       "      <td>20200316</td>\n",
       "      <td>1468748</td>\n",
       "      <td>biological products (no diagnostic substances)...</td>\n",
       "      <td>item management discussion analys be financial...</td>\n",
       "      <td>KOD</td>\n",
       "      <td>0.116291</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filename  \\\n",
       "6077  20200218_10-K_edgar_data_1360604_0001360604-20...   \n",
       "6078  20230228_10-K_edgar_data_1411579_0001411579-23...   \n",
       "6079  20170228_10-K_edgar_data_1163302_0001163302-17...   \n",
       "6080  20090331_10-K_edgar_data_43196_0000950144-09-0...   \n",
       "6081  20200316_10-K_edgar_data_1468748_0001564590-20...   \n",
       "\n",
       "                           Company Name  Filed As Of Date  Central Index Key  \\\n",
       "6077  healthcare trust of america, inc.          20200218            1360604   \n",
       "6078   amc entertainment holdings, inc.          20230228            1411579   \n",
       "6079           united states steel corp          20170228            1163302   \n",
       "6080                gray television inc          20090331              43196   \n",
       "6081               kodiak sciences inc.          20200316            1468748   \n",
       "\n",
       "                     Standard Industrial Classification  \\\n",
       "6077               real estate investment trusts [6798]   \n",
       "6078            services-motion picture theaters [7830]   \n",
       "6079  steel works, blast furnaces  rolling mills (co...   \n",
       "6080            television broadcasting stations [4833]   \n",
       "6081  biological products (no diagnostic substances)...   \n",
       "\n",
       "                                           Largest Text Ticker  \\\n",
       "6077  item management discussion analysis financial ...     HR   \n",
       "6078  item management discussion analysis financial ...    AMC   \n",
       "6079  item managements discussion analysis financial...      X   \n",
       "6080  item management discussion analysis financial ...    GTN   \n",
       "6081  item management discussion analys be financial...    KOD   \n",
       "\n",
       "      Percent Change (1 Week) Return Type  \n",
       "6077                 0.013804    Positive  \n",
       "6078                -0.124650    Negative  \n",
       "6079                -0.032025    Negative  \n",
       "6080                 0.406250    Positive  \n",
       "6081                 0.116291    Positive  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>20210310_10-K_edgar_data_1747079_0001747079-21...</td>\n",
       "      <td>bally's corp</td>\n",
       "      <td>20210310</td>\n",
       "      <td>1747079</td>\n",
       "      <td>hotels &amp; motels [7011]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>BALY</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>20140415_10-K_edgar_data_1108046_0001477932-14...</td>\n",
       "      <td>alumifuel power corp</td>\n",
       "      <td>20140415</td>\n",
       "      <td>1108046</td>\n",
       "      <td>industrial organic chemicals [2860]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>AFPW</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>20170331_10-K_edgar_data_829325_0001262463-17-...</td>\n",
       "      <td>spyr, inc.</td>\n",
       "      <td>20170331</td>\n",
       "      <td>829325</td>\n",
       "      <td>retail-eating &amp; drinking places [5810]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>SPYR</td>\n",
       "      <td>-0.001857</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>20140319_10-K_edgar_data_1364479_0001364479-14...</td>\n",
       "      <td>hertz global holdings inc</td>\n",
       "      <td>20140319</td>\n",
       "      <td>1364479</td>\n",
       "      <td>services-auto rental &amp; leasing (no drivers) [7...</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>HRI</td>\n",
       "      <td>-0.032139</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>20170228_10-K_edgar_data_1093557_0001093557-17...</td>\n",
       "      <td>dexcom inc</td>\n",
       "      <td>20170228</td>\n",
       "      <td>1093557</td>\n",
       "      <td>surgical &amp; medical instruments &amp; apparatus [3841]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>DXCM</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>20140227_10-K_edgar_data_60519_0001504337-14-0...</td>\n",
       "      <td>louisiana-pacific corp</td>\n",
       "      <td>20140227</td>\n",
       "      <td>60519</td>\n",
       "      <td>lumber &amp; wood products (no furniture) [2400]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>LPX</td>\n",
       "      <td>-0.019282</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>20230314_10-K_edgar_data_771266_0001493152-23-...</td>\n",
       "      <td>kopin corp</td>\n",
       "      <td>20230314</td>\n",
       "      <td>771266</td>\n",
       "      <td>semiconductors &amp; related devices [3674]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>KOPN</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>20211215_10-K_edgar_data_1410738_0001493152-21...</td>\n",
       "      <td>voip-pal.com inc</td>\n",
       "      <td>20211215</td>\n",
       "      <td>1410738</td>\n",
       "      <td>telephone &amp; telegraph apparatus [3661]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>VPLM</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>20220517_10-K_edgar_data_946581_0001628280-22-...</td>\n",
       "      <td>take two interactive software inc</td>\n",
       "      <td>20220517</td>\n",
       "      <td>946581</td>\n",
       "      <td>services-prepackaged software [7372]</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>TTWO</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>20020322_10-K_edgar_data_833640_0001012870-02-...</td>\n",
       "      <td>power integrations inc</td>\n",
       "      <td>20020322</td>\n",
       "      <td>833640</td>\n",
       "      <td>semiconductors &amp; related devices [3674]</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>POWI</td>\n",
       "      <td>0.014917</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filename  \\\n",
       "2482  20210310_10-K_edgar_data_1747079_0001747079-21...   \n",
       "4189  20140415_10-K_edgar_data_1108046_0001477932-14...   \n",
       "2806  20170331_10-K_edgar_data_829325_0001262463-17-...   \n",
       "625   20140319_10-K_edgar_data_1364479_0001364479-14...   \n",
       "5261  20170228_10-K_edgar_data_1093557_0001093557-17...   \n",
       "2187  20140227_10-K_edgar_data_60519_0001504337-14-0...   \n",
       "1558  20230314_10-K_edgar_data_771266_0001493152-23-...   \n",
       "889   20211215_10-K_edgar_data_1410738_0001493152-21...   \n",
       "463   20220517_10-K_edgar_data_946581_0001628280-22-...   \n",
       "5970  20020322_10-K_edgar_data_833640_0001012870-02-...   \n",
       "\n",
       "                           Company Name  Filed As Of Date  Central Index Key  \\\n",
       "2482                       bally's corp          20210310            1747079   \n",
       "4189               alumifuel power corp          20140415            1108046   \n",
       "2806                         spyr, inc.          20170331             829325   \n",
       "625           hertz global holdings inc          20140319            1364479   \n",
       "5261                         dexcom inc          20170228            1093557   \n",
       "2187             louisiana-pacific corp          20140227              60519   \n",
       "1558                         kopin corp          20230314             771266   \n",
       "889                    voip-pal.com inc          20211215            1410738   \n",
       "463   take two interactive software inc          20220517             946581   \n",
       "5970             power integrations inc          20020322             833640   \n",
       "\n",
       "                     Standard Industrial Classification  \\\n",
       "2482                             hotels & motels [7011]   \n",
       "4189                industrial organic chemicals [2860]   \n",
       "2806             retail-eating & drinking places [5810]   \n",
       "625   services-auto rental & leasing (no drivers) [7...   \n",
       "5261  surgical & medical instruments & apparatus [3841]   \n",
       "2187       lumber & wood products (no furniture) [2400]   \n",
       "1558            semiconductors & related devices [3674]   \n",
       "889              telephone & telegraph apparatus [3661]   \n",
       "463                services-prepackaged software [7372]   \n",
       "5970            semiconductors & related devices [3674]   \n",
       "\n",
       "                                           Largest Text Ticker  \\\n",
       "2482  item management discussion analysis financial ...   BALY   \n",
       "4189  item management discussion analysis financial ...   AFPW   \n",
       "2806  item management discussion analysis financial ...   SPYR   \n",
       "625   item managements discussion analysis financial...    HRI   \n",
       "5261  item management discussion analysis financial ...   DXCM   \n",
       "2187  item management discussion analysis financial ...    LPX   \n",
       "1558  item management discussion analysis financial ...   KOPN   \n",
       "889   item management discussion analysis financial ...   VPLM   \n",
       "463   item managements discussion analysis financial...   TTWO   \n",
       "5970  item managements discussion analysis financial...   POWI   \n",
       "\n",
       "      Percent Change (1 Week) Return Type  \n",
       "2482                 0.003616    Positive  \n",
       "4189                -0.125000    Negative  \n",
       "2806                -0.001857    Negative  \n",
       "625                 -0.032139    Negative  \n",
       "5261                 0.002559    Positive  \n",
       "2187                -0.019282    Negative  \n",
       "1558                -0.049505    Negative  \n",
       "889                 -0.076923    Negative  \n",
       "463                  0.004387    Positive  \n",
       "5970                 0.014917    Positive  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoded \"Return Type\" for different classification algorithms.\n",
    "0 = negative\n",
    "1 = positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification  \\\n",
       "0  services-computer integrated systems design [7...   \n",
       "1  savings institutions, not federally chartered ...   \n",
       "2                          operative builders [1531]   \n",
       "3                              life insurance [6311]   \n",
       "4          electric & other services combined [4931]   \n",
       "\n",
       "                                        Largest Text Ticker  \\\n",
       "0  item management discussion analysis financial ...   CLSK   \n",
       "1  item managements discussion analysis financial...   HFWA   \n",
       "2  item management discussion analysis financial ...    PHM   \n",
       "3  item management discussion analysis financial ...    MET   \n",
       "4  item managements discussion analysis financial...    EXC   \n",
       "\n",
       "   Percent Change (1 Week)  Return Type  \n",
       "0                -0.106524            0  \n",
       "1                 0.008755            1  \n",
       "2                 0.071569            1  \n",
       "3                 0.010058            1  \n",
       "4                 0.024268            1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Return Type\"] = df[\"Return Type\"].astype(\"category\")\n",
    "df[\"Return Type\"] = df[\"Return Type\"].cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add New Columns to Dataframe to hold results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "      <th>Random_Forest_CV</th>\n",
       "      <th>...</th>\n",
       "      <th>Word_Sentiment_Type_Loughran_McDonald</th>\n",
       "      <th>TextBlob_Sentiment_Score</th>\n",
       "      <th>TextBlob_Sentiment_Type</th>\n",
       "      <th>FinBERT_Positive_Sentence_Count</th>\n",
       "      <th>FinBERT_Neutral_Sentence_Count</th>\n",
       "      <th>FinBERT_Negative_Sentence_Count</th>\n",
       "      <th>FinBERT_Pos_minus_Neg_Score</th>\n",
       "      <th>FinBERT_Sentiment_Type</th>\n",
       "      <th>Chat_GPT_Sentiment</th>\n",
       "      <th>Chat_GPT_Sentiment_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification  \\\n",
       "0  services-computer integrated systems design [7...   \n",
       "1  savings institutions, not federally chartered ...   \n",
       "2                          operative builders [1531]   \n",
       "3                              life insurance [6311]   \n",
       "4          electric & other services combined [4931]   \n",
       "\n",
       "                                        Largest Text Ticker  \\\n",
       "0  item management discussion analysis financial ...   CLSK   \n",
       "1  item managements discussion analysis financial...   HFWA   \n",
       "2  item management discussion analysis financial ...    PHM   \n",
       "3  item management discussion analysis financial ...    MET   \n",
       "4  item managements discussion analysis financial...    EXC   \n",
       "\n",
       "   Percent Change (1 Week)  Return Type  Random_Forest_CV  ...  \\\n",
       "0                -0.106524            0               NaN  ...   \n",
       "1                 0.008755            1               NaN  ...   \n",
       "2                 0.071569            1               NaN  ...   \n",
       "3                 0.010058            1               NaN  ...   \n",
       "4                 0.024268            1               NaN  ...   \n",
       "\n",
       "   Word_Sentiment_Type_Loughran_McDonald  TextBlob_Sentiment_Score  \\\n",
       "0                                    NaN                       NaN   \n",
       "1                                    NaN                       NaN   \n",
       "2                                    NaN                       NaN   \n",
       "3                                    NaN                       NaN   \n",
       "4                                    NaN                       NaN   \n",
       "\n",
       "   TextBlob_Sentiment_Type  FinBERT_Positive_Sentence_Count  \\\n",
       "0                      NaN                              NaN   \n",
       "1                      NaN                              NaN   \n",
       "2                      NaN                              NaN   \n",
       "3                      NaN                              NaN   \n",
       "4                      NaN                              NaN   \n",
       "\n",
       "   FinBERT_Neutral_Sentence_Count  FinBERT_Negative_Sentence_Count  \\\n",
       "0                             NaN                              NaN   \n",
       "1                             NaN                              NaN   \n",
       "2                             NaN                              NaN   \n",
       "3                             NaN                              NaN   \n",
       "4                             NaN                              NaN   \n",
       "\n",
       "   FinBERT_Pos_minus_Neg_Score  FinBERT_Sentiment_Type  Chat_GPT_Sentiment  \\\n",
       "0                          NaN                     NaN                 NaN   \n",
       "1                          NaN                     NaN                 NaN   \n",
       "2                          NaN                     NaN                 NaN   \n",
       "3                          NaN                     NaN                 NaN   \n",
       "4                          NaN                     NaN                 NaN   \n",
       "\n",
       "   Chat_GPT_Sentiment_binary  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Random_Forest_CV'] = np.nan\n",
    "df['Random_Forest_TF_IDF'] = np.nan\n",
    "df['XGBoost_CV'] = np.nan\n",
    "df['XGBoost_CV_TF_IDF'] = np.nan \n",
    "df['Naive_Bayes_CV'] = np.nan\n",
    "df['Naive_Bayes_TF_IDF'] = np.nan\n",
    "df['Positive_Word_Count_Loughran_McDonald'] = np.nan\n",
    "df['Negative_Word_Count_Loughran_McDonald'] = np.nan\n",
    "df['Total Word Count_Loughran_McDonald'] = np.nan\n",
    "df[\"Word_Pos_minus_Neg_Score_Loughran_McDonald\"] = np.nan \n",
    "df['Word_Sentiment_Type_Loughran_McDonald'] = np.nan\n",
    "df['TextBlob_Sentiment_Score'] = np.nan  \n",
    "df['TextBlob_Sentiment_Type'] = np.nan \n",
    "df['FinBERT_Positive_Sentence_Count'] = np.nan\n",
    "df['FinBERT_Neutral_Sentence_Count'] = np.nan\n",
    "df['FinBERT_Negative_Sentence_Count'] = np.nan\n",
    "df[\"FinBERT_Pos_minus_Neg_Score\"] = np.nan\n",
    "df['FinBERT_Sentiment_Type'] = np.nan\n",
    "df['Chat_GPT_Sentiment'] = np.nan\n",
    "df['Chat_GPT_Sentiment_binary'] = np.nan\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vec = CountVectorizer(max_features=4000)\n",
    "data_features1 = bow_vec.fit_transform(df[\"Largest Text\"])\n",
    "data_features1 = data_features1.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6082, 4000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data_features1\n",
    "y1 = df[\"Return Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=4000)\n",
    "data_features2 = vectorizer.fit_transform(df[\"Largest Text\"])\n",
    "data_features2 = data_features2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6082, 4000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = data_features2\n",
    "y2 = df[\"Return Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 = CountVectorizer\n",
    "### 2 = TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to use your own path to your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest on CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the model on the entire dataset is: 0.51\n"
     ]
    }
   ],
   "source": [
    "clf_loaded = load('/Users/jamespavlicek/Desktop/QMST/4320/Project Final/random_forest_model_countvectorizer.joblib')\n",
    "\n",
    "predictions = clf_loaded.predict(X1)\n",
    "\n",
    "overall_accuracy = accuracy_score(df[\"Return Type\"], predictions)\n",
    "\n",
    "print(f\"Overall Accuracy of the model on the entire dataset is: {overall_accuracy:.2f}\")\n",
    "\n",
    "df['Random_Forest_CV'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2028 1037]\n",
      " [1913 1104]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(df[\"Return Type\"], predictions)\n",
    "\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the model on the entire dataset is: 0.51\n",
      "[0 1 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "clf_loaded_2 = load('/Users/jamespavlicek/Desktop/QMST/4320/Project Final/random_forest_model_tf_idf.joblib')\n",
    "\n",
    "predictions_2 = clf_loaded_2.predict(X2)\n",
    "\n",
    "overall_accuracy = accuracy_score(df[\"Return Type\"], predictions_2)\n",
    "\n",
    "print(f\"Overall Accuracy of the model on the entire dataset is: {overall_accuracy:.2f}\")\n",
    "\n",
    "df['Random_Forest_TF_IDF'] = predictions\n",
    "\n",
    "print(predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2093  972]\n",
      " [2031  986]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat_2 = confusion_matrix(df[\"Return Type\"], predictions_2)\n",
    "\n",
    "print(conf_mat_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost on CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the model on the entire dataset is: 0.52\n",
      "[0 1 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "xgboost_loaded_1 = load('/Users/jamespavlicek/Desktop/QMST/4320/Project Final/XGBoost_model_countvectorizer.joblib')\n",
    "\n",
    "predictions_3 = xgboost_loaded_1.predict(X1)\n",
    "\n",
    "overall_accuracy = accuracy_score(df[\"Return Type\"], predictions_3)\n",
    "\n",
    "print(f\"Overall Accuracy of the model on the entire dataset is: {overall_accuracy:.2f}\")\n",
    "\n",
    "df['XGBoost_CV'] = predictions_3\n",
    "\n",
    "print(predictions_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2554  511]\n",
      " [2437  580]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat_3 = confusion_matrix(df[\"Return Type\"], predictions_3)\n",
    "\n",
    "print(conf_mat_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the model on the entire dataset is: 0.51\n",
      "[0 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "xgboost_loaded_2 = load('/Users/jamespavlicek/Desktop/QMST/4320/Project Final/XGBoost_model_tf_idf.joblib')\n",
    "\n",
    "predictions_4 = xgboost_loaded_2.predict(X2)\n",
    "\n",
    "overall_accuracy = accuracy_score(df[\"Return Type\"], predictions_4)\n",
    "\n",
    "print(f\"Overall Accuracy of the model on the entire dataset is: {overall_accuracy:.2f}\")\n",
    "\n",
    "df['XGBoost_CV_TF_IDF'] = predictions_4\n",
    "\n",
    "print(predictions_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1923 1142]\n",
      " [1849 1168]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat_4 = confusion_matrix(df[\"Return Type\"], predictions_4)\n",
    "\n",
    "print(conf_mat_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the model on the entire dataset is: 0.49\n",
      "[0 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_loaded_1 = load('/Users/jamespavlicek/Desktop/QMST/4320/Project Final/naive_bayes_model_countvectorizer.joblib')\n",
    "\n",
    "predictions_5 = naive_bayes_loaded_1.predict(X1)\n",
    "\n",
    "overall_accuracy = accuracy_score(df[\"Return Type\"], predictions_5)\n",
    "\n",
    "print(f\"Overall Accuracy of the model on the entire dataset is: {overall_accuracy:.2f}\")\n",
    "\n",
    "df['Naive_Bayes_CV'] = predictions_5\n",
    "\n",
    "print(predictions_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2271  794]\n",
      " [2286  731]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat_5 = confusion_matrix(df[\"Return Type\"], predictions_5)\n",
    "\n",
    "print(conf_mat_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the model on the entire dataset is: 0.50\n",
      "[0 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_loaded_2 = load('/Users/jamespavlicek/Desktop/QMST/4320/Project Final/naive_bayes_model_tf_idf.joblib')\n",
    "\n",
    "predictions_6 = naive_bayes_loaded_2.predict(X2)\n",
    "\n",
    "overall_accuracy = accuracy_score(df[\"Return Type\"], predictions_6)\n",
    "\n",
    "print(f\"Overall Accuracy of the model on the entire dataset is: {overall_accuracy:.2f}\")\n",
    "\n",
    "df['Naive_Bayes_TF_IDF'] = predictions_6\n",
    "\n",
    "print(predictions_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 620 2445]\n",
      " [ 611 2406]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat_6 = confusion_matrix(df[\"Return Type\"], predictions_6)\n",
    "\n",
    "print(conf_mat_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire Text Sentiment (Textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Return Type  TextBlob_Sentiment_Score  TextBlob_Sentiment_Type\n",
      "0               0                  0.063592                      1.0\n",
      "1               1                  0.057926                      1.0\n",
      "2               1                  0.073174                      1.0\n",
      "3               1                  0.053829                      1.0\n",
      "4               1                  0.042621                      1.0\n",
      "...           ...                       ...                      ...\n",
      "6077            1                  0.021044                      0.0\n",
      "6078            0                  0.025346                      0.0\n",
      "6079            0                  0.020568                      0.0\n",
      "6080            1                  0.040332                      1.0\n",
      "6081            1                  0.033845                      1.0\n",
      "\n",
      "[6082 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Largest Text']\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    df.at[index, 'TextBlob_Sentiment_Score'] = sentiment\n",
    "\n",
    "    if sentiment > 0.03: \n",
    "        df.at[index, 'TextBlob_Sentiment_Type'] = int(1)\n",
    "    else:\n",
    "        df.at[index, 'TextBlob_Sentiment_Type'] = int(0)\n",
    "\n",
    "print(df[['Return Type', 'TextBlob_Sentiment_Score', 'TextBlob_Sentiment_Type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 837 2228]\n",
      " [ 882 2135]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat_7 = confusion_matrix(df[\"Return Type\"], df[\"TextBlob_Sentiment_Type\"])\n",
    "\n",
    "print(conf_mat_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loughran-McDonald Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is a frequency analysis of the text compared to a positive / negative word list from Bill McDonald at Notre Dame University. This dataset was derived from 10ks from 1993-2023. Soruce: https://sraf.nd.edu/loughranmcdonald-master-dictionary/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6082, 29)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Largest Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type</th>\n",
       "      <th>Random_Forest_CV</th>\n",
       "      <th>...</th>\n",
       "      <th>Word_Sentiment_Type_Loughran_McDonald</th>\n",
       "      <th>TextBlob_Sentiment_Score</th>\n",
       "      <th>TextBlob_Sentiment_Type</th>\n",
       "      <th>FinBERT_Positive_Sentence_Count</th>\n",
       "      <th>FinBERT_Neutral_Sentence_Count</th>\n",
       "      <th>FinBERT_Negative_Sentence_Count</th>\n",
       "      <th>FinBERT_Pos_minus_Neg_Score</th>\n",
       "      <th>FinBERT_Sentiment_Type</th>\n",
       "      <th>Chat_GPT_Sentiment</th>\n",
       "      <th>Chat_GPT_Sentiment_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>item management discussion analysis financial ...</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053829</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>item managements discussion analysis financial...</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification  \\\n",
       "0  services-computer integrated systems design [7...   \n",
       "1  savings institutions, not federally chartered ...   \n",
       "2                          operative builders [1531]   \n",
       "3                              life insurance [6311]   \n",
       "4          electric & other services combined [4931]   \n",
       "\n",
       "                                        Largest Text Ticker  \\\n",
       "0  item management discussion analysis financial ...   CLSK   \n",
       "1  item managements discussion analysis financial...   HFWA   \n",
       "2  item management discussion analysis financial ...    PHM   \n",
       "3  item management discussion analysis financial ...    MET   \n",
       "4  item managements discussion analysis financial...    EXC   \n",
       "\n",
       "   Percent Change (1 Week)  Return Type  Random_Forest_CV  ...  \\\n",
       "0                -0.106524            0                 1  ...   \n",
       "1                 0.008755            1                 0  ...   \n",
       "2                 0.071569            1                 1  ...   \n",
       "3                 0.010058            1                 1  ...   \n",
       "4                 0.024268            1                 1  ...   \n",
       "\n",
       "   Word_Sentiment_Type_Loughran_McDonald  TextBlob_Sentiment_Score  \\\n",
       "0                                    0.0                  0.063592   \n",
       "1                                    0.0                  0.057926   \n",
       "2                                    0.0                  0.073174   \n",
       "3                                    0.0                  0.053829   \n",
       "4                                    0.0                  0.042621   \n",
       "\n",
       "   TextBlob_Sentiment_Type  FinBERT_Positive_Sentence_Count  \\\n",
       "0                      1.0                              NaN   \n",
       "1                      1.0                              NaN   \n",
       "2                      1.0                              NaN   \n",
       "3                      1.0                              NaN   \n",
       "4                      1.0                              NaN   \n",
       "\n",
       "   FinBERT_Neutral_Sentence_Count  FinBERT_Negative_Sentence_Count  \\\n",
       "0                             NaN                              NaN   \n",
       "1                             NaN                              NaN   \n",
       "2                             NaN                              NaN   \n",
       "3                             NaN                              NaN   \n",
       "4                             NaN                              NaN   \n",
       "\n",
       "   FinBERT_Pos_minus_Neg_Score  FinBERT_Sentiment_Type  Chat_GPT_Sentiment  \\\n",
       "0                          NaN                     NaN                 NaN   \n",
       "1                          NaN                     NaN                 NaN   \n",
       "2                          NaN                     NaN                 NaN   \n",
       "3                          NaN                     NaN                 NaN   \n",
       "4                          NaN                     NaN                 NaN   \n",
       "\n",
       "   Chat_GPT_Sentiment_binary  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "data = pd.read_csv(\"/Users/jamespavlicek/Desktop/QMST/4320/Project Final/Loughran-McDonald_MasterDictionary.csv\")\n",
    "\n",
    "testing_df = data.copy()\n",
    "\n",
    "negative_word_list = []\n",
    "positive_word_list = []\n",
    "\n",
    "# Go through each row in the csv and see if there is a postive value in the Negative or Positive row\n",
    "for index, row in testing_df.iterrows():\n",
    "    if row['Negative'] > 0:\n",
    "        negative_word_list.append(row['Word'])\n",
    "    if row['Positive'] > 0:\n",
    "        positive_word_list.append(row['Word'])\n",
    "\n",
    "negative_word_list = [word.lower() for word in negative_word_list]\n",
    "positive_word_list = [word.lower() for word in positive_word_list]\n",
    "\n",
    "# Read the text and count the frequency of positive and negative words\n",
    "def count_neg_and_pos_words(text, negative_word_list, positive_word_list):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "\n",
    "    count_of_negative_words = 0 \n",
    "    count_of_positive_words = 0 \n",
    "    total_words = len(words)\n",
    "    for word in words:\n",
    "        word_lower = word.lower() \n",
    "        if word_lower in negative_word_list:\n",
    "            count_of_negative_words += 1\n",
    "        elif word_lower in positive_word_list:\n",
    "            count_of_positive_words += 1\n",
    "    \n",
    "    return count_of_positive_words, count_of_negative_words, total_words\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Largest Text'] \n",
    "    results = count_neg_and_pos_words(text, negative_word_list, positive_word_list)\n",
    "\n",
    "    # Load the results into the dataframe\n",
    "    df.at[index, 'Positive_Word_Count_Loughran_McDonald'] = results[0]\n",
    "    df.at[index, 'Negative_Word_Count_Loughran_McDonald'] = results[1]\n",
    "    df.at[index, 'Total Word Count_Loughran_McDonald'] = results[2]\n",
    "\n",
    "    # Calculate the Pos minus Neg Score \n",
    "    Pos_neg_score = results[0] - results[1]\n",
    "    df.at[index, \"Word_Pos_minus_Neg_Score_Loughran_McDonald\"] = Pos_neg_score \n",
    "\n",
    "    pos_word_ratio = results[0] / results[2]\n",
    "    neg_word_ratio = results[1] / results[2]\n",
    "    strength_ratio = pos_word_ratio - neg_word_ratio\n",
    "\n",
    "    if strength_ratio > 0:\n",
    "        df.at[index, 'Word_Sentiment_Type_Loughran_McDonald'] = 1\n",
    "    else:\n",
    "        df.at[index, 'Word_Sentiment_Type_Loughran_McDonald'] = 0\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2895  170]\n",
      " [2871  146]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat_8 = confusion_matrix(df[\"Return Type\"], df[\"Word_Sentiment_Type_Loughran_McDonald\"])\n",
    "\n",
    "print(conf_mat_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setence Sentiment (FinBERT) (Skipped - Takes 1 minute per row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://huggingface.co/yiyanghkust/finbert-tone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "# Function to perform sentiment analysis on a row\n",
    "def analyze_sentiment(index):\n",
    "    row = df_2.loc[index]\n",
    "    large_text_string = row['Largest Text']\n",
    "    sentences = nltk.tokenize.sent_tokenize(large_text_string)\n",
    "    filtered_sentences = [sentence for sentence in sentences if len(nltk.word_tokenize(sentence)) <= 100]\n",
    "    \n",
    "    if filtered_sentences:\n",
    "        results_3 = nlp(filtered_sentences)\n",
    "        count = {\"Positive\": 0, \"Neutral\": 0, \"Negative\": 0}\n",
    "        for item in results_3:\n",
    "            label = item['label']\n",
    "            if label in count:\n",
    "                count[label] += 1      \n",
    "        return index, count\n",
    "    else:\n",
    "        return index, {\"Positive\": 0, \"Neutral\": 0, \"Negative\": 0}\n",
    "\n",
    "# Load the FinBERT sentiment analysis model\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)\n",
    "\n",
    "# Call the analyze_sentiment() function and put the results to the dataframe\n",
    "for index in df_2.index:\n",
    "    index, count = analyze_sentiment(index)\n",
    "    print(index)\n",
    "    print(count)\n",
    "    df.loc[index, 'FinBERT_Positive_Sentence_Count'] = count['Positive']\n",
    "    df.loc[index, 'FinBERT_Neutral_Sentence_Count'] = count['Neutral']\n",
    "    df.loc[index, 'FinBERT_Negative_Sentence_Count'] = count['Negative']\n",
    "    Pos_neg_score = count['Positive'] - count['Negative']\n",
    "    df.loc[index, \"FinBERT_Pos_minus_Neg_Score\"] = Pos_neg_score \n",
    "\n",
    "    if Pos_neg_score > 0:\n",
    "        df.loc[index,'FinBERT_Sentiment_Type'] = 1\n",
    "    else:\n",
    "        df.loc[index,'FinBERT_Sentiment_Type'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_9 = confusion_matrix(df[\"Return Type\"], df['FinBERT_Sentiment_Type'])\n",
    "\n",
    "print(conf_mat_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat GPT API (Skipped - 1 minute per row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used code from chatgptmax package in order to send text chunks larger than 16k token. For this model you need acsess to Chat GPT API and a API key. Source: https://github.com/victoriadrake/chatgptmax in order to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os \n",
    "import re\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'ENTER_YOUR_API_KEY'\n",
    "\n",
    "client = OpenAI(api_key='ENTER_YOUR_API_KEY')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "df['Chat_GPT_Sentiment'] = np.nan\n",
    "df['Chat_GPT_Sentiment_binary'] = np.nan\n",
    "\n",
    "#openai.api_key = 'OPENAI_API_KEY'  # Replace with your actual API key\n",
    "\n",
    "def send(\n",
    "    prompt=None,\n",
    "    text_data=None,\n",
    "    chat_model=\"gpt-3.5-turbo-0125\",\n",
    "    model_token_limit=16000,\n",
    "    max_tokens=10000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Send the prompt at the start of the conversation and then send chunks of text_data to ChatGPT via the OpenAI API.\n",
    "    If the text_data is too long, it splits it into chunks and sends each chunk separately.\n",
    "\n",
    "    Args:\n",
    "    - prompt (str, optional): The prompt to guide the model's response.\n",
    "    - text_data (str, optional): Additional text data to be included.\n",
    "    - max_tokens (int, optional): Maximum tokens for each API call. Default is 2500.\n",
    "\n",
    "    Returns:\n",
    "    - list or str: A list of model's responses for each chunk or an error message.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the necessary arguments are provided\n",
    "    if not prompt:\n",
    "        return \"Error: Prompt is missing. Please provide a prompt.\"\n",
    "    if not text_data:\n",
    "        return \"Error: Text data is missing. Please provide some text data.\"\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.encoding_for_model(chat_model)\n",
    "\n",
    "    # Encode the text_data into token integers\n",
    "    token_integers = tokenizer.encode(text_data)\n",
    "\n",
    "    # Split the token integers into chunks based on max_tokens\n",
    "    chunk_size = max_tokens - len(tokenizer.encode(prompt))\n",
    "    chunks = [\n",
    "        token_integers[i : i + chunk_size]\n",
    "        for i in range(0, len(token_integers), chunk_size)\n",
    "    ]\n",
    "\n",
    "    # Decode token chunks back to strings\n",
    "    chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "    responses = []\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"To provide the context for the above prompt, I will send you text in parts. When I am finished, I will tell you 'ALL PARTS SENT'. Do not answer until you have received all the parts.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        messages.append({\"role\": \"user\", \"content\": chunk})\n",
    "\n",
    "        # Check if total tokens exceed the model's limit and remove oldest chunks if necessary\n",
    "        while (\n",
    "            sum(len(tokenizer.encode(msg[\"content\"])) for msg in messages)\n",
    "            > model_token_limit\n",
    "        ):\n",
    "            messages.pop(1)  # Remove the oldest chunk\n",
    "\n",
    "        response = client.chat.completions.create(model=chat_model, messages=messages)\n",
    "        chatgpt_response = response.choices[0].message\n",
    "        responses.append(chatgpt_response)\n",
    "\n",
    "    # Add the final \"ALL PARTS SENT\" message\n",
    "    messages.append({\"role\": \"user\", \"content\": \"ALL PARTS SENT\"})\n",
    "    response = client.chat.completions.create(model=chat_model, messages=messages)\n",
    "    final_response = response.choices[0].message\n",
    "    responses.append(final_response)\n",
    "\n",
    "    return responses\n",
    "\n",
    "def text(text):\n",
    "    \"\"\"\n",
    "    Cleans the provided text by removing URLs, email addresses, non-letter characters, and extra whitespace.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The input text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    - str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Remove email addresses\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"\", text)\n",
    "\n",
    "    # Remove everything that's not a letter (a-z, A-Z)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def summarize_text(tenk_text):\n",
    "    file_content = text(tenk_text)\n",
    "    # Define your prompt\n",
    "    prompt_text = \"You are a financial analyst and I am given you a portion of the item 7 of a SEC 10k report. Please summarize this text in around 5 sentences or 100 words. This text will later be used for sentiment analysis so make sure not to remove it in the summary. I will keep sending parts of the document and keep summarizing each part until I stop sending.\"\n",
    "    \n",
    "    # Send the file content to ChatGPT\n",
    "    responses = send(prompt=prompt_text, text_data=file_content)\n",
    "    \n",
    "    # Print the responses\n",
    "    text_summary = []\n",
    "    for response in responses:\n",
    "        #print(f'This is the response: {response}')\n",
    "\n",
    "        extracted_content = response.content\n",
    "        #print(f'This is the extracted_content: {extracted_content}')\n",
    "\n",
    "        text_summary.append(extracted_content)\n",
    "        \n",
    "    #print(f'This is the text_summary: {text_summary}.')\n",
    "    \n",
    "    return text_summary\n",
    "\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a financial analyst that conducts sentiment analysis on SEC 10-k documents. You respond in either 'Positive' or 'Negative'.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"I have a list of summaries from the item 7 of a SEC 10k report. The summaries provided are in the same order as the original 10k's item 7. Do not take into account any financial document I gave you previously, only look at the string of text that will be provided later in this prompt. What is the sentiment of the following text? (keep your answer to one word, Positive or Negative.) {text}\"}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    message_text = completion.choices[0].message.content\n",
    "    #print(message_text)\n",
    "    return message_text\n",
    "\n",
    "#Save the results to the dataframe\n",
    "for index, row in df_2.iterrows():\n",
    "    time.sleep(20)\n",
    "    tenk_text = row[\"Largest Text\"]\n",
    "    text_summary = summarize_text(tenk_text)\n",
    "    message_text = analyze_sentiment(text_summary)\n",
    "    print(f'The {index} 10k is : {message_text}')\n",
    "    \n",
    "    df.at[index, 'Chat_GPT_Sentiment'] = message_text\n",
    "\n",
    "    if message_text == \"Positive\":\n",
    "        df.at[index, 'Chat_GPT_Sentiment_binary'] = 1\n",
    "    else:\n",
    "        df.at[index, 'Chat_GPT_Sentiment_binary'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Largest Text'])\n",
    "\n",
    "df.to_csv('QMST_4320_Project_Final_Results_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmed down the dataset and fixed textblob and word sentiment for a more favorable Sensitivity & Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/jamespavlicek/Desktop/QMST/4320/Project Final/QMST_4320_Project_Final_Results_10_models - QMST_4320_Project_Final_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Filed As Of Date</th>\n",
       "      <th>Central Index Key</th>\n",
       "      <th>Standard Industrial Classification</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percent Change (1 Week)</th>\n",
       "      <th>Return Type_actual</th>\n",
       "      <th>Random_Forest_CV_pred</th>\n",
       "      <th>Random_Forest_TF_IDF_pred</th>\n",
       "      <th>XGBoost_CV_pred</th>\n",
       "      <th>XGBoost_CV_TF_IDF_pred</th>\n",
       "      <th>Naive_Bayes_CV_pred</th>\n",
       "      <th>Naive_Bayes_TF_IDF_pred</th>\n",
       "      <th>TextBlob_Sentiment_Type_adjusted_pred</th>\n",
       "      <th>Word_Sentiment_Type_Loughran_McDonald_adjusted_pred</th>\n",
       "      <th>FinBERT_Sentiment_Type_adjusted_pred</th>\n",
       "      <th>Chat_GPT_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211214_10-K_edgar_data_827876_0001663577-21-...</td>\n",
       "      <td>cleanspark, inc.</td>\n",
       "      <td>20211214</td>\n",
       "      <td>827876</td>\n",
       "      <td>services-computer integrated systems design [7...</td>\n",
       "      <td>CLSK</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220225_10-K_edgar_data_1046025_0001046025-22...</td>\n",
       "      <td>heritage financial corp /wa/</td>\n",
       "      <td>20220225</td>\n",
       "      <td>1046025</td>\n",
       "      <td>savings institutions, not federally chartered ...</td>\n",
       "      <td>HFWA</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210202_10-K_edgar_data_822416_0000822416-21-...</td>\n",
       "      <td>pultegroup inc/mi/</td>\n",
       "      <td>20210202</td>\n",
       "      <td>822416</td>\n",
       "      <td>operative builders [1531]</td>\n",
       "      <td>PHM</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190222_10-K_edgar_data_1099219_0001099219-19...</td>\n",
       "      <td>metlife inc</td>\n",
       "      <td>20190222</td>\n",
       "      <td>1099219</td>\n",
       "      <td>life insurance [6311]</td>\n",
       "      <td>MET</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230214_10-K_edgar_data_1109357_0001109357-23...</td>\n",
       "      <td>exelon corp</td>\n",
       "      <td>20230214</td>\n",
       "      <td>1109357</td>\n",
       "      <td>electric &amp; other services combined [4931]</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  20211214_10-K_edgar_data_827876_0001663577-21-...   \n",
       "1  20220225_10-K_edgar_data_1046025_0001046025-22...   \n",
       "2  20210202_10-K_edgar_data_822416_0000822416-21-...   \n",
       "3  20190222_10-K_edgar_data_1099219_0001099219-19...   \n",
       "4  20230214_10-K_edgar_data_1109357_0001109357-23...   \n",
       "\n",
       "                   Company Name  Filed As Of Date  Central Index Key  \\\n",
       "0              cleanspark, inc.          20211214             827876   \n",
       "1  heritage financial corp /wa/          20220225            1046025   \n",
       "2            pultegroup inc/mi/          20210202             822416   \n",
       "3                   metlife inc          20190222            1099219   \n",
       "4                   exelon corp          20230214            1109357   \n",
       "\n",
       "                  Standard Industrial Classification Ticker  \\\n",
       "0  services-computer integrated systems design [7...   CLSK   \n",
       "1  savings institutions, not federally chartered ...   HFWA   \n",
       "2                          operative builders [1531]    PHM   \n",
       "3                              life insurance [6311]    MET   \n",
       "4          electric & other services combined [4931]    EXC   \n",
       "\n",
       "   Percent Change (1 Week)  Return Type_actual  Random_Forest_CV_pred  \\\n",
       "0                -0.106524                   0                      0   \n",
       "1                 0.008755                   1                      0   \n",
       "2                 0.071569                   1                      1   \n",
       "3                 0.010058                   1                      1   \n",
       "4                 0.024268                   1                      0   \n",
       "\n",
       "   Random_Forest_TF_IDF_pred  XGBoost_CV_pred  XGBoost_CV_TF_IDF_pred  \\\n",
       "0                          0                1                       1   \n",
       "1                          0                1                       0   \n",
       "2                          1                1                       1   \n",
       "3                          1                1                       1   \n",
       "4                          0                1                       1   \n",
       "\n",
       "   Naive_Bayes_CV_pred  Naive_Bayes_TF_IDF_pred  \\\n",
       "0                    1                        1   \n",
       "1                    0                        1   \n",
       "2                    0                        0   \n",
       "3                    0                        0   \n",
       "4                    0                        1   \n",
       "\n",
       "   TextBlob_Sentiment_Type_adjusted_pred  \\\n",
       "0                                      1   \n",
       "1                                      1   \n",
       "2                                      1   \n",
       "3                                      1   \n",
       "4                                      1   \n",
       "\n",
       "   Word_Sentiment_Type_Loughran_McDonald_adjusted_pred  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  1     \n",
       "3                                                  1     \n",
       "4                                                  0     \n",
       "\n",
       "   FinBERT_Sentiment_Type_adjusted_pred  Chat_GPT_pred  \n",
       "0                                     0              0  \n",
       "1                                     1              1  \n",
       "2                                     1              1  \n",
       "3                                     0              0  \n",
       "4                                     0              0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2593, 18)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Filename', 'Company Name', 'Filed As Of Date', 'Central Index Key',\n",
      "       'Standard Industrial Classification', 'Ticker',\n",
      "       'Percent Change (1 Week)', 'Return Type_actual',\n",
      "       'Random_Forest_CV_pred', 'Random_Forest_TF_IDF_pred', 'XGBoost_CV_pred',\n",
      "       'XGBoost_CV_TF_IDF_pred', 'Naive_Bayes_CV_pred',\n",
      "       'Naive_Bayes_TF_IDF_pred', 'TextBlob_Sentiment_Type_adjusted_pred',\n",
      "       'Word_Sentiment_Type_Loughran_McDonald_adjusted_pred',\n",
      "       'FinBERT_Sentiment_Type_adjusted_pred', 'Chat_GPT_pred'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_meta.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual column name\n",
    "actual_column = 'Return Type_actual'\n",
    "actual = df[actual_column].astype(bool)\n",
    "\n",
    "# List your predicted columns here\n",
    "predicted_columns = ['Random_Forest_CV_pred', 'Random_Forest_TF_IDF_pred', 'XGBoost_CV_pred',\n",
    "       'XGBoost_CV_TF_IDF_pred', 'Naive_Bayes_CV_pred',\n",
    "       'Naive_Bayes_TF_IDF_pred', 'TextBlob_Sentiment_Type_adjusted_pred',\n",
    "       'Word_Sentiment_Type_Loughran_McDonald_adjusted_pred',\n",
    "       'FinBERT_Sentiment_Type_adjusted_pred', 'Chat_GPT_pred']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each model Preformance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Column</th>\n",
       "      <th>NIR</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_Forest_CV_pred</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.490551</td>\n",
       "      <td>0.561362</td>\n",
       "      <td>0.423308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random_Forest_TF_IDF_pred</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.490551</td>\n",
       "      <td>0.561362</td>\n",
       "      <td>0.423308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_CV_pred</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.476668</td>\n",
       "      <td>0.786223</td>\n",
       "      <td>0.182707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_CV_TF_IDF_pred</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.509063</td>\n",
       "      <td>0.755344</td>\n",
       "      <td>0.275188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive_Bayes_CV_pred</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.499422</td>\n",
       "      <td>0.270784</td>\n",
       "      <td>0.716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive_Bayes_TF_IDF_pred</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.495565</td>\n",
       "      <td>0.294537</td>\n",
       "      <td>0.686466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TextBlob_Sentiment_Type_adjusted_pred</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.502892</td>\n",
       "      <td>0.520190</td>\n",
       "      <td>0.486466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Word_Sentiment_Type_Loughran_McDonald_adjusted...</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.501735</td>\n",
       "      <td>0.535234</td>\n",
       "      <td>0.469925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FinBERT_Sentiment_Type_adjusted_pred</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.489009</td>\n",
       "      <td>0.440222</td>\n",
       "      <td>0.535338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chat_GPT_pred</td>\n",
       "      <td>0.512919</td>\n",
       "      <td>0.493251</td>\n",
       "      <td>0.520190</td>\n",
       "      <td>0.467669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Predicted Column       NIR  Accuracy  \\\n",
       "0                              Random_Forest_CV_pred  0.512919  0.490551   \n",
       "1                          Random_Forest_TF_IDF_pred  0.512919  0.490551   \n",
       "2                                    XGBoost_CV_pred  0.512919  0.476668   \n",
       "3                             XGBoost_CV_TF_IDF_pred  0.512919  0.509063   \n",
       "4                                Naive_Bayes_CV_pred  0.512919  0.499422   \n",
       "5                            Naive_Bayes_TF_IDF_pred  0.512919  0.495565   \n",
       "6              TextBlob_Sentiment_Type_adjusted_pred  0.512919  0.502892   \n",
       "7  Word_Sentiment_Type_Loughran_McDonald_adjusted...  0.512919  0.501735   \n",
       "8               FinBERT_Sentiment_Type_adjusted_pred  0.512919  0.489009   \n",
       "9                                      Chat_GPT_pred  0.512919  0.493251   \n",
       "\n",
       "   Sensitivity  Specificity  \n",
       "0     0.561362     0.423308  \n",
       "1     0.561362     0.423308  \n",
       "2     0.786223     0.182707  \n",
       "3     0.755344     0.275188  \n",
       "4     0.270784     0.716541  \n",
       "5     0.294537     0.686466  \n",
       "6     0.520190     0.486466  \n",
       "7     0.535234     0.469925  \n",
       "8     0.440222     0.535338  \n",
       "9     0.520190     0.467669  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [] \n",
    "\n",
    "for predicted_column in predicted_columns:\n",
    "    predicted = df[predicted_column].astype(bool)\n",
    "    \n",
    "    # No Information Rate (NIR)\n",
    "    NIR = actual.value_counts(normalize=True).max()\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(actual, predicted)\n",
    "    \n",
    "    # Sensitivity (Recall)\n",
    "    sensitivity = recall_score(actual, predicted)\n",
    "    \n",
    "    # Specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(actual, predicted).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Append the results to the list\n",
    "    results.append({'Predicted Column': predicted_column, \n",
    "                    'NIR': NIR, \n",
    "                    'Accuracy': accuracy, \n",
    "                    'Sensitivity': sensitivity, \n",
    "                    'Specificity': specificity})\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Predicted Column', 'NIR', 'Accuracy', 'Sensitivity', 'Specificity'])\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
